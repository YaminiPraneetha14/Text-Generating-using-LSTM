{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtt2LGio7p1q"
      },
      "source": [
        "# Long Short-term Memory for Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long Short-term Memory for Text Generation\n",
        "\n",
        "Use LSTM neural network to generate text from Nietzsche's writings\n",
        "\n",
        "Training Dataset is available online at https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
        "\n"
      ],
      "metadata": {
        "id": "uqbPr4R77rMu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GGK6geY7p1s"
      },
      "source": [
        "This notebook uses LSTM neural network to generate text from Nietzsche's writings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06uxEWyr7p1t"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, LSTM,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tASds0T67p1u"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vv801Fs7p1u"
      },
      "source": [
        "### Get the data\n",
        "Nietzsche's writing dataset is available online. The following code download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "c7TuSwbs7p1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887932c2-ac47-4dd3-a4b2-4331bf40c2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "600901/600901 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path = get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXev5N4I7p1u"
      },
      "source": [
        "### Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-crxBvB87p1u",
        "outputId": "f88bb47c-574a-404b-f8ca-645a3ffe7786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 600893\n"
          ]
        }
      ],
      "source": [
        "print('corpus length:', len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "SP4CP3Pe7p1v",
        "outputId": "7469c76a-8d5f-4e63-fb76-9406d04d1e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supposing that truth is a woman--what then? is there not ground\n",
            "for suspecting that all philosophers, in so far as they have been\n",
            "dogmatists, have failed to understand women--that the terrible\n",
            "seriousness and clumsy importunity with which they have usually paid\n",
            "their addresses to truth, have been unskilled and unseemly methods for\n",
            "winning a woman? certainly she has never allowed herself to be won; and\n",
            "at present every kind of dogma stands with sad and discouraged mien--if,\n",
            "indeed, it stands at all!\n"
          ]
        }
      ],
      "source": [
        "print(text[10:513])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liNAmjSu7p1v",
        "outputId": "633290a8-7327-4afa-84c7-88641280aa40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars: 57\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "# total nomber of characters\n",
        "print('total chars:', len(chars))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V65sDq_u7p1v"
      },
      "source": [
        "### Clean data\n",
        "\n",
        "We cut the text in sequences of maxlen characters with a jump size of 3.\n",
        "The features for each example is a matrix of size maxlen*num of chars.\n",
        "The label for each example is a vector of size num of chars, which represents the next character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "eVMAAuD57p1w"
      },
      "outputs": [],
      "source": [
        "# create (character, index) and (index, character) dictionary\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f3H7I6n7p1w",
        "outputId": "cc5ba0ab-5908-437b-ed6a-a59a6f23e861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sequences: 200285\n"
          ]
        }
      ],
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSGCoGCa7p1w",
        "outputId": "c541a167-c086-441a-b44d-0558ab30971a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b1fdc504c468>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
            "<ipython-input-8-b1fdc504c468>:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ],
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCNfWt0l7p1w"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4FAsGpC7p1w"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw-mx1X47p1w"
      },
      "source": [
        "we need a recurrent layer with input shape (maxlen, len(chars)) and a dense layer with output size  len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IdC96Ue17p1x"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model():\n",
        "    lstm = Sequential()\n",
        "    lstm.add(LSTM(128,input_shape=(40,len(chars))))\n",
        "    lstm.add(layers.BatchNormalization())\n",
        "    lstm.add(Dropout(0.1))\n",
        "    lstm.add(Dense((len(chars)),activation = 'softmax'))\n",
        "    lstm.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return lstm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model = build_lstm_model()"
      ],
      "metadata": {
        "id": "r1tnpIZKaktl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-2joRj7p1x"
      },
      "source": [
        "### Inspect the model\n",
        "\n",
        "Use the `.summary` method to print a simple description of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MvF4Cj67p1x",
        "outputId": "35d9d17e-49fe-4c80-b10a-3034874af438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               95232     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 57)                7353      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103,097\n",
            "Trainable params: 102,841\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNDIYKMG7p1x"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "TVesshTc7p1x"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "T3JHq1lh7p1x"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(14)\n",
        "class PrintLoss(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, _):\n",
        "        # Function invoked at end of each epoch. Prints generated text.\n",
        "        print()\n",
        "        print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "        for diversity in [0.5, 1.0]:\n",
        "            print('----- diversity:', diversity)\n",
        "\n",
        "            generated = ''\n",
        "            sentence = text[start_index: start_index + maxlen]\n",
        "            generated += sentence\n",
        "            print('----- Generating with seed: \"' + sentence + '\"')\n",
        "            sys.stdout.write(generated)\n",
        "\n",
        "            for i in range(400):\n",
        "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "                for t, char in enumerate(sentence):\n",
        "                    x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "                preds = model.predict(x_pred, verbose=0)[0]\n",
        "                next_index = sample(preds, diversity)\n",
        "                next_char = indices_char[next_index]\n",
        "\n",
        "                sentence = sentence[1:] + next_char\n",
        "\n",
        "                sys.stdout.write(next_char)\n",
        "                sys.stdout.flush()\n",
        "            print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "HAq2BNlV7p1x",
        "outputId": "bbfb50ab-43ac-4f2b-c6c5-d23c75233d6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 2.4096 - accuracy: 0.3152\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"n\n",
            "\"prudently and apart.\" wisdom: that se\"\n",
            "n\n",
            "\"prudently and apart.\" wisdom: that sect\n",
            "ch thon thelly\n",
            "ch the\n",
            "ch\n",
            "the\n",
            "\n",
            "full ns\n",
            "\n",
            "xpllict ll\n",
            "the th\n",
            "\n",
            "\n",
            "xpllonthy\n",
            "\n",
            "noll\n",
            "\n",
            "xprelly\n",
            "chall\n",
            "\n",
            "nsthe\n",
            "\n",
            "folly\n",
            "\n",
            "hall\n",
            "\n",
            "xplly\n",
            "hinl\n",
            "\n",
            "lf\n",
            "ch the\n",
            "ch\n",
            "phinsthin the pr noplly\n",
            "phis\n",
            "ch\n",
            "chimy lly\n",
            "knon\n",
            "\n",
            "hilly\n",
            "nct\n",
            "\n",
            "no\n",
            "pllly\n",
            "nctlly\n",
            "blly\n",
            "lf\n",
            "the\n",
            "plecthes\n",
            "\n",
            "xthepliclly\n",
            "thiclly\n",
            "\n",
            "f\n",
            "cullinclly\n",
            "nolly; the hich\n",
            "\n",
            "hin lly\n",
            "chint\n",
            "\n",
            "nthe thom\n",
            "\n",
            "xplly\n",
            "ch the ss no\n",
            "lly ff\n",
            "ch\n",
            "phiclly\n",
            "\n",
            "xpllinthin\n",
            "\n",
            "xpsontint\n",
            "\n",
            "fullly\n",
            "thiclly,\n",
            "thilly\n",
            "n\n",
            "\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"n\n",
            "\"prudently and apart.\" wisdom: that se\"\n",
            "n\n",
            "\"prudently and apart.\" wisdom: that se\n",
            "sh ll\n",
            "\": fully tisn the\n",
            "btelf-lfolly\n",
            "ins lf rs lid\n",
            "\n",
            "nllly ny\n",
            "\n",
            "ha\n",
            "llymplolly\n",
            "thecly\n",
            "hons ésf\n",
            "llken phy\n",
            "[5f\n",
            "ll ghilléfinl oncull,\n",
            ";\n",
            "_\n",
            "ch. lf ll\n",
            "\n",
            "knont ly\n",
            "\n",
            "xpliplonly\n",
            "bllonchi(ll\n",
            "pherysten\n",
            "t; nl thely hirplyglett eht\n",
            "\n",
            "furll hy ns\n",
            "hy lly thot\n",
            "chyce?; n\n",
            "\n",
            "hophillsy\n",
            "\n",
            "pllftunck\n",
            "non: \"s\n",
            "\n",
            "pplincoplf;ry\n",
            "noply\n",
            "th yrclith\n",
            "phand\n",
            "\": \"ar\n",
            "y\n",
            "\n",
            "_inn.\n",
            "\n",
            "[xmmand\n",
            "\n",
            "junclotlhy\n",
            "74.\n",
            "\n",
            "xpllulf\n",
            "ullly!\n",
            "\n",
            "\n",
            "xrlecund chill ins\n",
            "\n",
            "fll\n",
            "1252/1252 [==============================] - 213s 168ms/step - loss: 2.4096 - accuracy: 0.3152 - val_loss: 2.8737 - val_accuracy: 0.1779\n",
            "Epoch 2/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 2.2340 - accuracy: 0.3453\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"selves to worship stone, stupidity,\n",
            "grav\"\n",
            "selves to worship stone, stupidity,\n",
            "graven whach hed hore ho has bo hak ho her her has chand char shing no her ass hes hor heves as no bel on the shan sher has be her hever bean shond har hach als hos hard hal his cher hal dand har his she h ch her bo bed hal ho hore chas hich che cor han ho hand her hand has hach sole her ber be has hing hes has hal had ho hh hh hach hin dichir chal cher anch ch chever his chling her her har hon bece t\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"selves to worship stone, stupidity,\n",
            "grav\"\n",
            "selves to worship stone, stupidity,\n",
            "grave and prind whyhe  hos ehe nos the serald ha phinge ben an rever chaching incons ar dlyald chek shel sion fher nas bounc all gong bokn æuch over\"--behtpres bed encer---ar here sosich alc 05. pher male foledd hach holedg conctorn ghl gersprasicht sh\n",
            "ch chas liks which ar dischaw \"hbs \"hoch sh arur bvel ibe har acelly corschicch sor hokn a[marendr dhes do hind hase calle bokin s chicescan sh reverch\n",
            "1252/1252 [==============================] - 217s 173ms/step - loss: 2.2340 - accuracy: 0.3453 - val_loss: 2.4430 - val_accuracy: 0.3088\n",
            "Epoch 3/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 2.1498 - accuracy: 0.3647\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"rinsic will to power, which is precisely\"\n",
            "rinsic will to power, which is precisely in ar every \"ing care ank in the re the rekery eve the treily an the greing in the \" or in in in make in is and and is hich reen the be exeren lo king he sered the keve will and one with is in the sure \"be ouge \"\"\"ke \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"rinsic will to power, which is precisely\"\n",
            "rinsic will to power, which is precisely. elevi. y\n",
            "bukers piref. the ja.. -dokn 4. re fure the \"gy euve hirke ive in oud even.. \"kikn wicke ny \" ulre! \"weus the bil, lis by bee preresy. bel \"ly ly in is le thy evint wo juse mul be even ind grealsue \"co ster yf isplonitage ; 0ure, ner oun fuib begirize the nomake ace rung mos hirre in thes ing\n",
            "ane as nory merily yourt.\n",
            "y; antens, ery ele asbike sile\n",
            "notre \" evertoung \": \"ever, logh reerg\n",
            "1252/1252 [==============================] - 222s 177ms/step - loss: 2.1498 - accuracy: 0.3647 - val_loss: 2.2475 - val_accuracy: 0.3471\n",
            "Epoch 4/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 2.0732 - accuracy: 0.3849\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"s neither a\n",
            "particularly good man nor a \"\n",
            "s neither a\n",
            "particularly good man nor a to the der and mas the lat the cout is ther to the whoch seed cance the the dermon so not stin cons and and des not be ner and the hers crally silly to ner as whe not cons and hat and and not the mort coll sen and and and and the her and and man lat the gros, the ant the ras erst can the leat an the ons to the the sar the which sor dens in the soll gar and it the wat derat what in sal erving on th\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"s neither a\n",
            "particularly good man nor a \"\n",
            "s neither a\n",
            "particularly good man nor a now the sorthind in belo thi goinl aces sut car mans in ciss to ar not the wern of nan smant this smon, tre why thy hat or wrec latern nes and the deew or \"dall. in ow red latt ench in orl zes tore land nen they, cind which ne scerthe smo ther mod w, to ken3.  n which on there ebtsent his wisl fren ono not onas shin sod sirat on whe creto the, sor, moncon gloons onl in mang nals bes whicl yif an w\n",
            "1252/1252 [==============================] - 213s 170ms/step - loss: 2.0732 - accuracy: 0.3849 - val_loss: 2.2198 - val_accuracy: 0.3564\n",
            "Epoch 5/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 2.0106 - accuracy: 0.4010\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" a\n",
            "religious significance of all existen\"\n",
            " a\n",
            "religious significance of all existenting, on the\n",
            "perions. it enepeross, in the possopoused\n",
            "soppersess and woren the pereopher of the soblece of may the evely and pownos on the sone of the lif the heosopers of\n",
            "whel would the in the is in of ene pows and powion\n",
            "conspicion of is concesoly and has a so every, who has of beear, so poosod on arspolous of consely one and one is and stine of wild in ous bele sopens of the\n",
            "powers of phis poo\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" a\n",
            "religious significance of all existen\"\n",
            " a\n",
            "religious significance of all existen, is every it\n",
            "beceiries selmitame to alwerongess.\n",
            "is i sols acy and in deel to in bo and gow tho ras alponey\n",
            "and cimpelf ant wild coltance with its nere ow\n",
            "has pitleced. eusow or goowe,h caning. haw\n",
            "dison is solve beiwn the felceces and, theive\n",
            "with so it be its acophivesiniss morte, bomusbally an way souber to enaly it\n",
            "is unlespeophe one, the wisla1!\" beition\n",
            "al a penally only thit\n",
            "eapouos, with \n",
            "1252/1252 [==============================] - 220s 176ms/step - loss: 2.0106 - accuracy: 0.4010 - val_loss: 1.9799 - val_accuracy: 0.4042\n",
            "Epoch 6/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 1.9563 - accuracy: 0.4167\n",
            "----- Generating text after Epoch: 5\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"\n",
            "honours himself in them, and in the rig\"\n",
            "\n",
            "honours himself in them, and in the rightad and\n",
            "and in the gentance the sungermand the staght in the\n",
            "\n",
            "\n",
            "111. the ses it grenged of thas the raghong and the manker and and and and\n",
            "angared to the morations and the abelangents and with decingrod and senerang to the\n",
            "sund and that be the were denting be and the sagnes the gond\n",
            "and and in the sange and and the wor dingernated in the grat the\n",
            "goight and and to the the some the grand the\n",
            "gonger\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"\n",
            "honours himself in them, and in the rig\"\n",
            "\n",
            "honours himself in them, and in the right\n",
            "gungrroud dencirn was\n",
            "cesplitadd spensess\n",
            "to sustake? the a sumbeicagecting seffint; and ofthing of he man: man\" and tals, one so vaurgertion murtith,\n",
            " he fgot of that antention grensing innouted,\n",
            "retunguran of that unefmentrings of rem consore,\n",
            "knows a prasak frenung hat to ko wand wat\n",
            "a grated in ruse and the crulated that progato7.\n",
            "\n",
            "\n",
            "\n",
            "f se to gomer mor the canticn assith as of cansrating the\n",
            "1252/1252 [==============================] - 229s 183ms/step - loss: 1.9563 - accuracy: 0.4167 - val_loss: 1.9506 - val_accuracy: 0.4138\n",
            "Epoch 7/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 1.9090 - accuracy: 0.4286\n",
            "----- Generating text after Epoch: 6\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"2\n",
            "\n",
            "=the traditional error of philosopher\"\n",
            "2\n",
            "\n",
            "=the traditional error of philosopheres, with undirstrand and pentappes, the persopation, and what be now hesosest and and\n",
            "perpossion, the every and which a the powand with they have he reas for has of the has every and many as and supenting, and that who fal and and and scared timong the wish\n",
            "persappess, and for of the have the word supption\n",
            "and and now peritime, and indess and perhaps which sene and\n",
            "persops and and and resoch and d\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"2\n",
            "\n",
            "=the traditional error of philosopher\"\n",
            "2\n",
            "\n",
            "=the traditional error of philosopher, and thes onest, and foo he hisspority, and\n",
            "pessaffict as of than inquarefus. be wes\n",
            "\"eloed\" byse, powo(thy spirsod is is uscarsalians\n",
            "what wean--oreys the heldeanity was have has gloog ampof and\n",
            "resprous what the mostrigumakeve, which as\n",
            "who owimanify the seges dovoust--be mosptent\n",
            "quesy a hadutasting. desubluaged and incearn and\n",
            "permandsoated). prowloght,\n",
            "an a propsigiond cinters of with, for a\n",
            "1252/1252 [==============================] - 219s 175ms/step - loss: 1.9090 - accuracy: 0.4286 - val_loss: 1.9087 - val_accuracy: 0.4241\n",
            "Epoch 8/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 1.8650 - accuracy: 0.4411\n",
            "----- Generating text after Epoch: 7\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" present, the mother of morality, great\n",
            "\"\n",
            " present, the mother of morality, great\n",
            "it the self--leation of the plases, and what the seling is the sace and and and the manion, and and the sasentical consentual the self interpance of the love of the gorsitient, this with it is accestice of a comperces and accouded the soul time who latue of the sereand is the reald in undertion the selige of the sulourted the sensess, the lage as the sting out perhaps the senting of the comstor to\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" present, the mother of morality, great\n",
            "\"\n",
            " present, the mother of morality, great\n",
            "guebre, praywand alonly noungerulm on the fasenonger, its augnterrity of waht stively adesse, ond ins3quentediouly dim=cained and of immelf readance his a their prosence am orking, to the shifich chame and aundifition: and the opsious insmitnceseding of thing in the tiget, and casmion \"mayt--oply\" of the say the righticuntuly, which us the langes, to thate canterque they cantentherthy, geing is is\n",
            "1252/1252 [==============================] - 222s 177ms/step - loss: 1.8650 - accuracy: 0.4411 - val_loss: 1.8328 - val_accuracy: 0.4556\n",
            "Epoch 9/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 1.8277 - accuracy: 0.4514\n",
            "----- Generating text after Epoch: 8\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ck hides his tail from every eye--and ca\"\n",
            "ck hides his tail from every eye--and can fast the ever the essest and conscience, in the suchority and sacking is not the men it it is is a man the itself it latter the moralice, and the deare, the the man experially the gainers of the sasters, this stiment, him of the the man formed the fired and senery of an the more canicy rementre the man it is net a cerman for as of an in the mist to be man the stretide, whee is genition and the i\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ck hides his tail from every eye--and ca\"\n",
            "ck hides his tail from every eye--and canicience--as the alle: and cals unselftre, gid--mactired than con9cties to on the migr and\n",
            "sufferming, impirstions: the usen that is even his conssiond, and pitrituce, lited lefect they thepers contiment, i meteling he peaver it is cliftic\n",
            "lied, even potally opes, in chitess abstiricy, and diffecticep do gany, and thes ancespermentisses,esrsusareption man regerality whic, a repusted, is even, for,\n",
            "1252/1252 [==============================] - 218s 174ms/step - loss: 1.8277 - accuracy: 0.4514 - val_loss: 1.8215 - val_accuracy: 0.4542\n",
            "Epoch 10/10\n",
            "1252/1252 [==============================] - ETA: 0s - loss: 1.7912 - accuracy: 0.4617\n",
            "----- Generating text after Epoch: 9\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"the evil after-effect of some particular\"\n",
            "the evil after-effect of some particulare the reearity and and the precentions and\n",
            "sunter and what whan the stree of the mander when he consented of the free men and not in\n",
            "persand the concenter in the for the something the seever not into recience and the concerity last the\n",
            "proble man of the such mative have been the suffered the\n",
            "spection, in the sumpation with as life and and all the present the does not present in the\n",
            "devers will be \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"the evil after-effect of some particular\"\n",
            "the evil after-effect of some particulare,\n",
            "in prepeans to the wild mandu to of tray kon\n",
            "most everyw is, of a link impo noce colfunded there ofet reases wawn koo darn a good\n",
            "\"99.\n",
            "\"uncountgerter brenever'watione aging in amous: which\n",
            "hat incalleysess, hy have and headw of guests of\n",
            "humbelf-lequeder, rage, which wound a an our\n",
            "of resenturly--one nubse incoldent which with what\n",
            "his it cansing fro as freeiticy foving apore ende conelisg\n",
            "and \n",
            "1252/1252 [==============================] - 216s 173ms/step - loss: 1.7912 - accuracy: 0.4617 - val_loss: 1.7653 - val_accuracy: 0.4727\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "BATCH = 128\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "history = model.fit(x, y,\n",
        "                    batch_size = BATCH,\n",
        "                    epochs = EPOCHS,\n",
        "                    validation_split = 0.2,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [early_stop, PrintLoss()])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}